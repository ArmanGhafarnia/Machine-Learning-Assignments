# -*- coding: utf-8 -*-
"""knn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AO6RM4nUlCj1Egt3-mNNzAVfVHZcEKwq
"""

import numpy as np
import pandas as pd
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from collections import Counter
import matplotlib.pyplot as plt

data_set = pd.read_csv('/content/drive/MyDrive/hw1/Disease_symptom_and_patient_profile_dataset.csv')    #read table
data_set.head(10)

label_encoder = LabelEncoder()                                               # changing names to values  0,1,2,...
data_set['Fever'] = label_encoder.fit_transform(data_set['Fever'])

label_encoder = LabelEncoder()
data_set['Cough'] = label_encoder.fit_transform(data_set['Cough'])

label_encoder = LabelEncoder()
data_set['Fatigue'] = label_encoder.fit_transform(data_set['Fatigue'])

label_encoder = LabelEncoder()
data_set['Difficulty Breathing'] = label_encoder.fit_transform(data_set['Difficulty Breathing'])

label_encoder = LabelEncoder()
data_set['Gender'] = label_encoder.fit_transform(data_set['Gender'])

label_encoder = LabelEncoder()
data_set['Blood Pressure'] = label_encoder.fit_transform(data_set['Blood Pressure'])

label_encoder = LabelEncoder()
data_set['Cholesterol Level'] = label_encoder.fit_transform(data_set['Cholesterol Level'])

data_set.head(5)

onehot = OneHotEncoder(sparse=False)     # creat onehotencoder we want array not sparse matrix
disease = onehot.fit_transform(data_set[['Disease']])  #convert disease column to onehot
disease_column = pd.DataFrame(disease, columns=onehot.get_feature_names_out(['Disease'])) #create new columns from name of diseases
data_set = data_set.drop('Disease', axis=1)   #remove the disease column     #axis -> column  labels - > row
data_set = pd.concat([disease_column, data_set], axis=1)  #add new columns to the table


data_set.head(5)

x = data_set.iloc[:,:-1]   #all inputs except last column(predict value)
y = data_set.iloc[:,-1]    #all rows in last column(predict value)
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)  #split data_set for learning

def knn(x_train, y_train, x_test, k=5):
    distances = [np.linalg.norm(np.array(x) - np.array(x_test)) for x in x_train.values]   #count norm
    k_indices = np.argsort(distances)[:k]                           #find k-best
    k_nearest_labels = [y_train.iloc[i] for i in k_indices]         #labels of k-best

    most_common = Counter(k_nearest_labels).most_common(1)          #find more common
    return most_common[0][0]

y_pred = []
for _, x in x_test.iterrows():
    prediction = knn(x_train, y_train, x)             #do knn for each row  and use x_test
    y_pred.append(prediction)

accuracy = accuracy_score(y_test, y_pred)         #find accuracy
print(accuracy)

y_test = label_encoder.fit_transform(y_test)
y_pred = label_encoder.fit_transform(y_pred)      #convert targets from their class to numerical

fpr, tpr, threshholds = roc_curve(y_test, y_pred)  #return arrays of fpr , tpr
roc_auc = auc(fpr, tpr)  #area under plot


plt.plot(fpr, tpr, color='deeppink',  label='accuracy = %f' % roc_auc)
plt.xlabel('FPR')
plt.ylabel('TPR')

plt.legend(loc="lower right")
plt.show()

